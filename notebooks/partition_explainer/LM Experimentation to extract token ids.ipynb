{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForMaskedLM, AutoModelForSeq2SeqLM \n",
    "import shap\n",
    "import scipy as sp\n",
    "import nlp\n",
    "import torch\n",
    "from shap.utils import safe_isinstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.is_decoder=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2Config' object has no attribute 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-ce741c553448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPT2Config' object has no attribute 'decoder'"
     ]
    }
   ],
   "source": [
    "model.config.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Who was Jim Henson ? Jim Henson was a\"\n",
    "indexed_tokens = tokenizer.encode(text)\n",
    "\n",
    "# Convert indexed tokens in a PyTorch tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8241, 373, 5395, 367, 19069, 5633, 5395, 367, 19069, 373, 257]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indexed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8241,   373,  5395,   367, 19069,  5633,  5395,   367, 19069,   373,\n",
       "           257]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 50257])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was Jim Henson? Jim Henson was a great'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = outputs[0]\n",
    "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
    "predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.is_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('sshleifer/distilbart-xsum-12-6')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-xsum-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((1,1))*43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-baa95259b04f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreTrainedModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_isinstance(obj, class_path_str):\n",
    "    \"\"\"\n",
    "    Acts as a safe version of isinstance without having to explicitly\n",
    "    import packages which may not exist in the users environment.\n",
    "\n",
    "    Checks if obj is an instance of type specified by class_path_str.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj: Any\n",
    "        Some object you want to test against\n",
    "    class_path_str: str or list\n",
    "        A string or list of strings specifying full class paths\n",
    "        Example: `sklearn.ensemble.RandomForestRegressor`\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    bool: True if isinstance is true and the package exists, False otherwise\n",
    "    \"\"\"\n",
    "    if isinstance(class_path_str, str):\n",
    "        class_path_strs = [class_path_str]\n",
    "    elif isinstance(class_path_str, list) or isinstance(class_path_str, tuple):\n",
    "        class_path_strs = class_path_str\n",
    "    else:\n",
    "        class_path_strs = ['']\n",
    "    \n",
    "    # try each module path in order\n",
    "    for class_path_str in class_path_strs:\n",
    "        if \".\" not in class_path_str:\n",
    "            raise ValueError(\"class_path_str must be a string or list of strings specifying a full \\\n",
    "                module path to a class. Eg, 'sklearn.ensemble.RandomForestRegressor'\")\n",
    "\n",
    "        # Splits on last occurence of \".\"\n",
    "        module_name, class_name = class_path_str.rsplit(\".\", 1)\n",
    "\n",
    "        # here we don't check further if the model is not imported, since we shouldn't have\n",
    "        # an object of that types passed to us if the model the type is from has never been\n",
    "        # imported. (and we don't want to import lots of new modules for no reason)\n",
    "        if module_name not in sys.modules:\n",
    "            continue\n",
    "\n",
    "        module = sys.modules[module_name]\n",
    "        \n",
    "        #Get class\n",
    "        _class = getattr(module, class_name, None)\n",
    "        \n",
    "        if _class is None:\n",
    "            continue\n",
    "        \n",
    "        if isinstance(obj, _class):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "safe_isinstance(model,\"transformers.PreTrainedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run_shap_env_kernel",
   "language": "python",
   "name": "run_shap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
